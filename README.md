# Image Classification Using CNN
CNNs used for image classification can often be viewed in two parts, where the first part learns a represen-tation of the image data — or “encoding” — and the second learns a mapping from this image encoding to4
the output space.  Our CNN will follow this schema, and the output space will be the five class labels weare considering.  The image encoder will be composed of convolutional layers, which maintain the spatialstructure of the image data by sliding filters with learned weights across the image. Once we have our imageencoding, we will use fully connected layers to learn a non-linear combination of this representation, andideally map this representation into a linearly-separable space that we can easily classify.  Between layers,we will add non-linear activation functions that allow the network to learn a non-linear mapping.
# Image Classification Using Autoencoder
In many cases, we may have a large amount of unlabeled data.  Such unlabeled data may still be usefulif we can find a way to learn a good representation of the underlying structure.  The general task of thisform, calledunsupervised learning, involves learning NOT how to predict the output label given the inputfeature-vector, but instead the internal structure of the input relative to other data points.  There are manyarchitectures and training methods for doing unsupervised learning with neural nets; here, we’ll focus onautoencoders.We consider a good representation of our data to be a compact representation in a lower-dimensional space,since it would require our model to learn the simpler underlying structure of the data instead of memorizingspecific features of the data.  Specifically, ifXis a space of possible food images, we want to learn ad-dimensional representation of the observed elements ofX, wheredis much smaller than the dimensions ofX. To learn such a representation, we can employ a functionencoder :X →Rd, which maps input imagesto thed-dimensional representation.  However, without a semantic representation of the important features(e.g. labels), we cannot directly train a network to learn the functionencoder.Instead of requiring labels, let’s utilize what we do have:  data.  Instead of learningencoder  :X →Rddirectly, we can learn an identity functionident :X → X.  Now, we have both the inputs and the outputs,so  we  can  learn  this  function.   We  seek  to  approximate  the  identity  function  by  a  functional  form  thatcompresses and then decompresses the input data. We can break this function down into two parts:ident =decoder◦encoder, whereencoder :X →Rdanddecoder :Rd→ X. Our training pairs for learning thisfunction will be of the form( ̄x, ̄x), where ̄xis a food image. Intuitively, the learned compressor (encoder)will  throw  away  all  irrelevant  aspects  of  the  data  and  keep  only  what  is  essential  for  the  decompressor(decoder) to reconstruct the data. This will allow us to find a good representation of the data.A neural network that implements this idea is called anautoencoder. Note: in general, the performance ofa neural network increases significantly with the amount of data.  Thus, we will use both the training andtest images (even though we don’t have labels for the test images). This corresponds to 12000 training and4000 test images.  The remaining 4000 validation images will be used to evaluate the performance of theautoencoder.
